{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def data_normalization(data):\n",
    "    # 获取所有数值型数据 注意 这里目前传递的是引用，非其它数据类型\n",
    "    numeric_features = data.dtypes[data.dtypes != 'object'].index\n",
    "\n",
    "    data[numeric_features] = data[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "    # 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "    data[numeric_features] = data[numeric_features].fillna(0)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = './PRSA_data_dropna.csv'\n",
    "\n",
    "dt = pd.read_csv(csv_path)\n",
    "\n",
    "X_pd = dt.loc[:,['DEWP','TEMP','PRES','cbwd','Iws','Is','Ir']] # 'year','month','day','hour',\n",
    "Y_pd = dt.loc[:,'pm2.5']\n",
    "\n",
    "# normalization\n",
    "X_norm_pd = data_normalization(X_pd)\n",
    "\n",
    "X = X_norm_pd.values.astype(float)\n",
    "Y = Y_pd.values.astype(int)\n",
    "\n",
    "Y = np.reshape(Y,(-1,1))\n",
    "\n",
    "# TODO:这里按照project要求进行抽取 已完成\n",
    "X_test, y_test = X[[i for i in range(X.shape[0]) if i % 7 == 6]][:, 0:], Y[[i for i in range(Y.shape[0]) if i % 7 == 6]][:, 0]\n",
    "X_train, y_train = X[[i for i in range(X.shape[0]) if i % 7 != 6]][:, 0:], Y[[i for i in range(Y.shape[0]) if i % 7 != 6]][:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of RandomForestRegressor: 0.4387778096511499\n",
      "R-squared value of ExtraTreesRegressor: 0.40381754132988323\n",
      "R-squared value of GradientBoostingRegressor: 0.3920382457288726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ss_X=StandardScaler()\n",
    "# ss_y=StandardScaler()\n",
    "#\n",
    "# #标准化处理\n",
    "# X_train=ss_X.fit_transform(X_train)\n",
    "# X_test=ss_X.fit_transform(X_test)\n",
    "# y_train=ss_y.fit_transform(y_train)\n",
    "# y_test=ss_y.fit_transform(y_test)\n",
    "\n",
    "#分别导入普通随机森林回归模型、极端随机森林回归模型、梯度提升树回归模型\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor,GradientBoostingRegressor\n",
    "\n",
    "rfr=RandomForestRegressor()\n",
    "rfr.fit(X_train,y_train)\n",
    "rfr_y_predict=rfr.predict(X_test)\n",
    "\n",
    "\n",
    "etr=ExtraTreesRegressor()\n",
    "etr.fit(X_train,y_train)\n",
    "etr_y_predict=etr.predict(X_test)\n",
    "\n",
    "gbr=GradientBoostingRegressor()\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_y_predict=gbr.predict(X_test)\n",
    "\n",
    "\n",
    "#对三种集成模型进行性能评价\n",
    "print('R-squared value of RandomForestRegressor:',rfr.score(X_test,y_test))\n",
    "print('R-squared value of ExtraTreesRegressor:',etr.score(X_test,y_test))\n",
    "print('R-squared value of GradientBoostingRegressor:',gbr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.4445183600305871, 0.9030973391580317)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model evaluation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr_1 = rfr.fit(X_train, y_train)\n",
    "# lr_1.predict(X_test)\n",
    "r2_score(y_test, lr_1.predict(X_test)), r2_score(y_train, lr_1.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      "[197.66666667 100.5         95.83333333 ...  13.5          9.\n",
      "  11.33333333]\n",
      "Test set R^2: 0.44\n"
     ]
    }
   ],
   "source": [
    "# knn 回归\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "reg = KNeighborsRegressor(n_neighbors=6)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "\"\"\"打印对于测试集的预测值\"\"\"\n",
    "print(\"Test set predictions:\\n{}\".format(reg.predict(X_test)))\n",
    "\n",
    "\"\"\"打印测试集上的误差\"\"\"\n",
    "print(\"Test set R^2: {:.2f}\".format(reg.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SVR regressor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n",
      "max: 50.0 \tmin: 5.0 \taverage: 22.532806324110677\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32me:\\Study_file\\MA234\\project_2022\\MA234\\ensemble_learning\\test1.ipynb Cell 4'\u001B[0m in \u001B[0;36m<cell line: 23>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     <a href='vscode-notebook-cell:/e%3A/Study_file/MA234/project_2022/MA234/ensemble_learning/test1.ipynb#ch0000003?line=20'>21</a>\u001B[0m X_train\u001B[39m=\u001B[39mss_X\u001B[39m.\u001B[39mfit_transform(X_train)\n\u001B[0;32m     <a href='vscode-notebook-cell:/e%3A/Study_file/MA234/project_2022/MA234/ensemble_learning/test1.ipynb#ch0000003?line=21'>22</a>\u001B[0m X_test\u001B[39m=\u001B[39mss_X\u001B[39m.\u001B[39mfit_transform(X_test)\n\u001B[1;32m---> <a href='vscode-notebook-cell:/e%3A/Study_file/MA234/project_2022/MA234/ensemble_learning/test1.ipynb#ch0000003?line=22'>23</a>\u001B[0m y_train\u001B[39m=\u001B[39mss_y\u001B[39m.\u001B[39;49mfit_transform(y_train)\n\u001B[0;32m     <a href='vscode-notebook-cell:/e%3A/Study_file/MA234/project_2022/MA234/ensemble_learning/test1.ipynb#ch0000003?line=23'>24</a>\u001B[0m y_test\u001B[39m=\u001B[39mss_y\u001B[39m.\u001B[39mfit_transform(y_test)\n\u001B[0;32m     <a href='vscode-notebook-cell:/e%3A/Study_file/MA234/project_2022/MA234/ensemble_learning/test1.ipynb#ch0000003?line=26'>27</a>\u001B[0m \u001B[39m#分别导入普通随机森林回归模型、极端随机森林回归模型、梯度提升树回归模型\u001B[39;00m\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:699\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=694'>695</a>\u001B[0m \u001B[39m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=695'>696</a>\u001B[0m \u001B[39m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=696'>697</a>\u001B[0m \u001B[39mif\u001B[39;00m y \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=697'>698</a>\u001B[0m     \u001B[39m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=698'>699</a>\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mfit(X, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mfit_params)\u001B[39m.\u001B[39mtransform(X)\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=699'>700</a>\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=700'>701</a>\u001B[0m     \u001B[39m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=701'>702</a>\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mfit(X, y, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mfit_params)\u001B[39m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:730\u001B[0m, in \u001B[0;36mStandardScaler.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=727'>728</a>\u001B[0m \u001B[39m# Reset internal state before fitting\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=728'>729</a>\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_reset()\n\u001B[1;32m--> <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=729'>730</a>\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:766\u001B[0m, in \u001B[0;36mStandardScaler.partial_fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=732'>733</a>\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=733'>734</a>\u001B[0m \u001B[39mOnline computation of mean and std on X for later scaling.\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=734'>735</a>\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=762'>763</a>\u001B[0m \u001B[39m    Fitted scaler.\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=763'>764</a>\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=764'>765</a>\u001B[0m first_call \u001B[39m=\u001B[39m \u001B[39mnot\u001B[39;00m \u001B[39mhasattr\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mn_samples_seen_\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m--> <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=765'>766</a>\u001B[0m X \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_validate_data(X, accept_sparse\u001B[39m=\u001B[39;49m(\u001B[39m'\u001B[39;49m\u001B[39mcsr\u001B[39;49m\u001B[39m'\u001B[39;49m, \u001B[39m'\u001B[39;49m\u001B[39mcsc\u001B[39;49m\u001B[39m'\u001B[39;49m),\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=766'>767</a>\u001B[0m                         estimator\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m, dtype\u001B[39m=\u001B[39;49mFLOAT_DTYPES,\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=767'>768</a>\u001B[0m                         force_all_finite\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mallow-nan\u001B[39;49m\u001B[39m'\u001B[39;49m, reset\u001B[39m=\u001B[39;49mfirst_call)\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=768'>769</a>\u001B[0m n_features \u001B[39m=\u001B[39m X\u001B[39m.\u001B[39mshape[\u001B[39m1\u001B[39m]\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/preprocessing/_data.py?line=770'>771</a>\u001B[0m \u001B[39mif\u001B[39;00m sample_weight \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:421\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=418'>419</a>\u001B[0m     out \u001B[39m=\u001B[39m X\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=419'>420</a>\u001B[0m \u001B[39melif\u001B[39;00m \u001B[39misinstance\u001B[39m(y, \u001B[39mstr\u001B[39m) \u001B[39mand\u001B[39;00m y \u001B[39m==\u001B[39m \u001B[39m'\u001B[39m\u001B[39mno_validation\u001B[39m\u001B[39m'\u001B[39m:\n\u001B[1;32m--> <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=420'>421</a>\u001B[0m     X \u001B[39m=\u001B[39m check_array(X, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mcheck_params)\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=421'>422</a>\u001B[0m     out \u001B[39m=\u001B[39m X\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/base.py?line=422'>423</a>\u001B[0m \u001B[39melse\u001B[39;00m:\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=60'>61</a>\u001B[0m extra_args \u001B[39m=\u001B[39m \u001B[39mlen\u001B[39m(args) \u001B[39m-\u001B[39m \u001B[39mlen\u001B[39m(all_args)\n\u001B[0;32m     <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=61'>62</a>\u001B[0m \u001B[39mif\u001B[39;00m extra_args \u001B[39m<\u001B[39m\u001B[39m=\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[1;32m---> <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=62'>63</a>\u001B[0m     \u001B[39mreturn\u001B[39;00m f(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[0;32m     <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=64'>65</a>\u001B[0m \u001B[39m# extra_args > 0\u001B[39;00m\n\u001B[0;32m     <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=65'>66</a>\u001B[0m args_msg \u001B[39m=\u001B[39m [\u001B[39m'\u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m=\u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m'\u001B[39m\u001B[39m.\u001B[39mformat(name, arg)\n\u001B[0;32m     <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=66'>67</a>\u001B[0m             \u001B[39mfor\u001B[39;00m name, arg \u001B[39min\u001B[39;00m \u001B[39mzip\u001B[39m(kwonly_args[:extra_args],\n\u001B[0;32m     <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=67'>68</a>\u001B[0m                                  args[\u001B[39m-\u001B[39mextra_args:])]\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:637\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=634'>635</a>\u001B[0m     \u001B[39m# If input is 1D raise error\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=635'>636</a>\u001B[0m     \u001B[39mif\u001B[39;00m array\u001B[39m.\u001B[39mndim \u001B[39m==\u001B[39m \u001B[39m1\u001B[39m:\n\u001B[1;32m--> <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=636'>637</a>\u001B[0m         \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=637'>638</a>\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mExpected 2D array, got 1D array instead:\u001B[39m\u001B[39m\\n\u001B[39;00m\u001B[39marray=\u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m.\u001B[39m\u001B[39m\\n\u001B[39;00m\u001B[39m\"\u001B[39m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=638'>639</a>\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=639'>640</a>\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=640'>641</a>\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mif it contains a single sample.\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m.\u001B[39mformat(array))\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=642'>643</a>\u001B[0m \u001B[39m# make sure we actually converted to numeric:\u001B[39;00m\n\u001B[0;32m    <a href='file:///d%3A/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=643'>644</a>\u001B[0m \u001B[39mif\u001B[39;00m dtype_numeric \u001B[39mand\u001B[39;00m array\u001B[39m.\u001B[39mdtype\u001B[39m.\u001B[39mkind \u001B[39min\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mOUSV\u001B[39m\u001B[39m\"\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}