{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('PRSA_data.csv')\n",
    "data = data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X_y = data.iloc[:, 5:]\n",
    "# y = data.iloc[:, 5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 将cbwd数据转换成onehot编码方便进行线性回归\n",
    "cbwd_one_hot = dict(zip(set(X_y['cbwd']), range(4)))\n",
    "cbwd_one_hot_inverse = dict(zip(range(4), set(X_y['cbwd'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "\n",
    "import copy\n",
    "\n",
    "X_cbwd = copy.deepcopy(X_y['cbwd'].values)\n",
    "X_cbwd_new = np.asarray(X_cbwd)\n",
    "for i, item in enumerate(X_cbwd):\n",
    "    X_cbwd_new[i] = cbwd_one_hot[item]\n",
    "\n",
    "X_y['cbwd'] = X_cbwd_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_y_numpy = X_y.values\n",
    "X_test, y_test = X_y_numpy[[i for i in range(X_y_numpy.shape[0]) if i % 7 == 6]][:, 1:], X_y_numpy[[i for i in range(\n",
    "    X_y_numpy.shape[0]) if i % 7 == 6]][:, 0]\n",
    "X_train, y_train = X_y_numpy[[i for i in range(X_y_numpy.shape[0]) if i % 7 != 6]][:, 1:], X_y_numpy[[i for i in range(\n",
    "    X_y_numpy.shape[0]) if i % 7 != 6]][:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.23806855735835586, 0.23635745357956917)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr_1 = LinearRegression().fit(X_train, y_train)\n",
    "# lr_1.predict(X_test)\n",
    "r2_score(y_test, lr_1.predict(X_test)), r2_score(y_train, lr_1.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m lr_1 \u001B[38;5;241m=\u001B[39m LinearRegression()\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# lr_1.predict(X_test)\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[43mf1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m, f1_score(y_train, lr_1\u001B[38;5;241m.\u001B[39mpredict(X_train))\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m extra_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(all_args)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extra_args \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# extra_args > 0\u001B[39;00m\n\u001B[0;32m     66\u001B[0m args_msg \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(name, arg)\n\u001B[0;32m     67\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m name, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(kwonly_args[:extra_args],\n\u001B[0;32m     68\u001B[0m                                  args[\u001B[38;5;241m-\u001B[39mextra_args:])]\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1068\u001B[0m, in \u001B[0;36mf1_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m    949\u001B[0m \u001B[38;5;129m@_deprecate_positional_args\u001B[39m\n\u001B[0;32m    950\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf1_score\u001B[39m(y_true, y_pred, \u001B[38;5;241m*\u001B[39m, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    951\u001B[0m              sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    952\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \n\u001B[0;32m    954\u001B[0m \u001B[38;5;124;03m    The F1 score can be interpreted as a weighted average of the precision and\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1066\u001B[0m \u001B[38;5;124;03m    modified with ``zero_division``.\u001B[39;00m\n\u001B[0;32m   1067\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1068\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfbeta_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1070\u001B[0m \u001B[43m                       \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1071\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m extra_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(all_args)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extra_args \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# extra_args > 0\u001B[39;00m\n\u001B[0;32m     66\u001B[0m args_msg \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(name, arg)\n\u001B[0;32m     67\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m name, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(kwonly_args[:extra_args],\n\u001B[0;32m     68\u001B[0m                                  args[\u001B[38;5;241m-\u001B[39mextra_args:])]\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1192\u001B[0m, in \u001B[0;36mfbeta_score\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1074\u001B[0m \u001B[38;5;129m@_deprecate_positional_args\u001B[39m\n\u001B[0;32m   1075\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfbeta_score\u001B[39m(y_true, y_pred, \u001B[38;5;241m*\u001B[39m, beta, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1076\u001B[0m                 average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1077\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the F-beta score.\u001B[39;00m\n\u001B[0;32m   1078\u001B[0m \n\u001B[0;32m   1079\u001B[0m \u001B[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001B[39;00m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1192\u001B[0m     _, _, f, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1193\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1194\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1196\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1197\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mf-score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1198\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1199\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m extra_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(all_args)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extra_args \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# extra_args > 0\u001B[39;00m\n\u001B[0;32m     66\u001B[0m args_msg \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(name, arg)\n\u001B[0;32m     67\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m name, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(kwonly_args[:extra_args],\n\u001B[0;32m     68\u001B[0m                                  args[\u001B[38;5;241m-\u001B[39mextra_args:])]\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1461\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m beta \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbeta should be >=0 in the F-beta score\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1461\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1462\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1465\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1274\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1270\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m   1271\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m   1272\u001B[0m                      \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[1;32m-> 1274\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1275\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[0;32m   1276\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m   1277\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:92\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     89\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 92\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     93\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(type_true, type_pred))\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m     96\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of unknown and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lr_1 = LinearRegression().fit(X_train, y_train)\n",
    "# lr_1.predict(X_test)\n",
    "f1_score(y_test, lr_1.predict(X_test)), f1_score(y_train, lr_1.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}